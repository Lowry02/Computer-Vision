{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e885357",
   "metadata": {},
   "source": [
    "# Project 1: Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec917e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# used to reload the imported modules on save\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import utils as u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac8fd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import least_squares\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import yaml\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6246ecf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "grid_size = (8,11)\n",
    "square_size = 11\n",
    "\n",
    "# getting the images path\n",
    "images_pathname = \"../images_and_poses_for_project_assignment/\"\n",
    "images_path = [os.path.join(images_pathname, imagename) for imagename in os.listdir(images_pathname) if imagename.endswith(\".png\")]\n",
    "poses_path = [os.path.join(images_pathname, pose) for pose in os.listdir(images_pathname) if pose.endswith(\".yaml\")]\n",
    "\n",
    "# Sorting the lists of strings in numerical order\n",
    "images_path.sort(key=lambda x: int(x.split('_')[-1].split('.')[0]))\n",
    "poses_path.sort(key=lambda x: int(x.split('_')[-1].split('.')[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea2aa30",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0624b8d",
   "metadata": {},
   "source": [
    "Calibrate using the Zhang procedure [Zhang, 2002], i.e., find the intrinsic parameters $K$ and, for each image, the pair of $R, t$ (extrinsic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d53b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "V = []\n",
    "all_H = []  # saving the homographies for each image\n",
    "\n",
    "# getting the homographies\n",
    "for img in images_path:\n",
    "    _, H = u.get_homography(img, grid_size, square_size)\n",
    "    all_H.append(H)\n",
    "    \n",
    "    v_12 = u.get_v_vector(H, 1, 2)\n",
    "    v_11 = u.get_v_vector(H, 1, 1)\n",
    "    v_22 = u.get_v_vector(H, 2, 2)\n",
    "    \n",
    "    V.append(v_12)\n",
    "    V.append(v_11 - v_22)\n",
    "    \n",
    "# computing params\n",
    "V = np.array(V)\n",
    "K = u.get_intrinsic(V)\n",
    "\n",
    "# computing extrinsic for one image\n",
    "all_R = []\n",
    "all_t = []\n",
    "\n",
    "for H in all_H:\n",
    "    R, t = u.get_extrinsic(K, H)\n",
    "    all_R.append(R)\n",
    "    all_t.append(t)\n",
    "\n",
    "# TODO: make a better log\n",
    "print(\"Example params: \\n\")\n",
    "print(f\"- K -\\n{K}\\n\")\n",
    "print(f\"- R -\\n{all_R[0]}\\n\")\n",
    "print(f\"- t - \\n{all_t[0]}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a42e113",
   "metadata": {},
   "source": [
    "## Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce322dde",
   "metadata": {},
   "source": [
    "Choose one of the calibration images and compute the total reprojection error (`Lecture 3, page 45`) for all the grid points (adding a figure with the reprojected points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1222de49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the image and extrinsics\n",
    "img_path = images_path[1]\n",
    "R1 = all_R[1]\n",
    "t1 = all_t[1]\n",
    "\n",
    "# combining R and t\n",
    "P = u.get_projection_matrix(K, R1, t1)\n",
    "\n",
    "corners = u.get_corners(img_path, grid_size)\n",
    "projected_corners = []\n",
    "\n",
    "error = 0\n",
    "for index, corner in enumerate(corners):\n",
    "    u_coord = corner[0]\n",
    "    v_coord = corner[1]\n",
    "\n",
    "    grid_size_cv2 = tuple(reversed(grid_size))\n",
    "    u_index, v_index = np.unravel_index(index, grid_size_cv2)\n",
    "\n",
    "    # the coordinates of the corner w.r.t. the reference corner at position (0,0) of the corners array\n",
    "    x_mm = (u_index) * square_size\n",
    "    y_mm = (v_index) * square_size\n",
    "\n",
    "    point_m = np.array([x_mm, y_mm, 0, 1])\n",
    "\n",
    "    projected_u, projected_v = u.project(point_m, P)[0]\n",
    "    projected_corners.append((projected_u, projected_v))\n",
    "    \n",
    "    error += (projected_u - u_coord)**2 + (projected_v - v_coord)**2\n",
    "\n",
    "print(f\"Error: {error:.2f}\")\n",
    "print(f\"Mean error per corner: {error/len(corners):.2f}\")\n",
    "\n",
    "# showing the projected corners\n",
    "image = cv2.imread(img_path)\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # type: ignore\n",
    "\n",
    "for corner in projected_corners:\n",
    "    u_coord, v_coord = int(corner[0]), int(corner[1])\n",
    "    cv2.circle(image_rgb, (u_coord, v_coord), radius=5, color=(255, 0, 0), thickness=-1)\n",
    "\n",
    "px.imshow(image_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4f2c75",
   "metadata": {},
   "source": [
    "## Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28b4b80",
   "metadata": {},
   "source": [
    "Superimpose an object (for instance, a cylinder as in Fig. 1), to the calibration plane, in 25 images of your choice and check the correctness of the results by visual inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab7545a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(0)\n",
    "NUM_IMAGES_TO_PROCESS = 25\n",
    "\n",
    "images_indices = random.sample(range(len(images_path)), NUM_IMAGES_TO_PROCESS)\n",
    "\n",
    "# 3D parameters of the cylinder (remain fixed for all projections)\n",
    "radius_mm = 22.0\n",
    "height_mm = 80.0\n",
    "\n",
    "# Positioning consistent with the origin of the checkerboard (e.g. 4 squares, 4 squares)\n",
    "center_x_mm = 5 * square_size \n",
    "center_y_mm = 4 * square_size\n",
    "num_sides_cyl = 30 # Cylinder resolution\n",
    "num_height_slices_cyl = 5\n",
    "\n",
    "superimposed_image_list = []\n",
    "\n",
    "for i in images_indices:\n",
    "    img_path = images_path[i]\n",
    "    R_i = all_R[i]\n",
    "    t_i = all_t[i]\n",
    "    P = u.get_projection_matrix(K, R_i, t_i)\n",
    "    \n",
    "    superimposed_image = u.superimpose_cylinder(\n",
    "        img_path=img_path, \n",
    "        P=P,\n",
    "        radius=radius_mm, \n",
    "        height=height_mm, \n",
    "        center_x=center_x_mm, \n",
    "        center_y=center_y_mm,\n",
    "        num_sides=num_sides_cyl,\n",
    "        num_height_slices=num_height_slices_cyl\n",
    "    )\n",
    "    \n",
    "    superimposed_image_list.append(superimposed_image)\n",
    "    \n",
    "px.imshow(superimposed_image_list[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a92f916",
   "metadata": {},
   "source": [
    "## Exercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436fef78",
   "metadata": {},
   "source": [
    "Optionally, you could carry out an experiment similar to the one reported in `Lecture 3, p. 65`, plotting the standard deviation of the principal point (entries $u_0$ and $v_0$ of the calibration matrix $K$) as a function of the number of images used for calibration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ed4ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "max_N_images = 20\n",
    "N_images = list(range(3, max_N_images + 1))\n",
    "n_samples = 100\n",
    "\n",
    "# since V is a stack of two equations per image,\n",
    "# I can use them to compute K instead of recomputing V each time\n",
    "index_to_select = list(range(0, len(V), 2))\n",
    "\n",
    "u0_std = []\n",
    "v0_std = []\n",
    "\n",
    "for n_images in range(3, max_N_images + 1):\n",
    "    current_sample = 1\n",
    "    principal_point_coord = []\n",
    "    while current_sample <= n_samples:\n",
    "        selected_images = np.array(random.sample(index_to_select, n_images))\n",
    "        _V = np.concatenate([V[selected_images], V[selected_images + 1]])\n",
    "\n",
    "        # some matrices could be not positive definite -> no solution\n",
    "        try:\n",
    "            K = u.get_intrinsic(np.array(_V))\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        principal_point_coord.append([K[0,2], K[1,2]])\n",
    "        current_sample += 1\n",
    "    \n",
    "    principal_point_coord = np.stack(principal_point_coord)\n",
    "    _u0_std, _v0_std = principal_point_coord.std(axis=0)\n",
    "    u0_std.append(_u0_std.item())\n",
    "    v0_std.append(_v0_std.item())\n",
    "    \n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(N_images, u0_std, marker='o', label='u_0_std')\n",
    "plt.plot(N_images, v0_std, marker='o', label='v_0_std')\n",
    "plt.xlabel('Number of Images')\n",
    "plt.ylabel('Standard Deviation')\n",
    "plt.title('Standard Deviation vs Number of Images')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1726dddb",
   "metadata": {},
   "source": [
    "## Exercise 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85303da",
   "metadata": {},
   "source": [
    "Optionally, you could compare the estimated $R, t$ with the ones stored in the files `pose_[index].yaml`, respectively in the fields $R_{CS}$ and $T_{CS}$. A possible way to compare two rotation matrices $R_A$ and $R_B$ is computing the Frobenius norm of the difference: $||R_A − R_B||_F$, but this comparison is not particularly meaningful. A better option is:\n",
    "- Compute the rotation matrix from frame $A$ to frame $B$: $R_{AB} = R_BR_A^T$\n",
    "- Compute the corresponding angle of rotation: $$ \\theta = \\arccos\\left(\\frac{tr(R_{AB}) - 1}{2}\\right), $$ where $|\\theta|$ is a measure of how the two rotation matrices differ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c0d56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_errors = []\n",
    "t_errors = []\n",
    "\n",
    "for i, pose in enumerate(poses_path[:5]):\n",
    "    with open(pose, 'r') as file:\n",
    "        data = yaml.safe_load(file)\n",
    "        R = all_R[i]\n",
    "        t = all_t[i]\n",
    "        R_CS = np.array(data[\"R_CS\"]).reshape(3,3)\n",
    "        t_CS = np.array(data[\"T_CS\"]) * 1000    # in our code we consider millimiters, in yaml file meters\n",
    "        \n",
    "        R_AB = R_CS @ R.T\n",
    "        R_errors.append(np.absolute(np.arccos((np.trace(R_AB) - 1) / 2)))\n",
    "        t_errors.append(np.linalg.norm(t - t_CS))\n",
    "        \n",
    "# Boxplot for R_errors\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot(R_errors, tick_labels=['R_errors'])\n",
    "plt.ylabel('Error - Angle in radians')\n",
    "plt.title('R Errors')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Boxplot for t_errors\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot(t_errors, tick_labels=['t_errors'])\n",
    "plt.ylabel('Error - Euclidean Distance')\n",
    "plt.title('t Errors')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaec735d",
   "metadata": {},
   "source": [
    "## Exercise 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a170cf",
   "metadata": {},
   "source": [
    "Optionally, you could print a checkerboard and apply the previous steps to a set of images acquired with your own smartphone, webcam or digital camera (thus, calibrating your device)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfdbd8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5dcef5ee",
   "metadata": {},
   "source": [
    "## Exercise 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d7cadd",
   "metadata": {},
   "source": [
    "Optionally, you could minimize the reprojection error (instead of the algebraic one), using the Maximum Likelihood Estimation approach suggested in Section 3.2 of [Zhang, 2002]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0706ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rodrigues Formula reference:\n",
    "# https://en.wikipedia.org/wiki/Axis%E2%80%93angle_representation\n",
    "\n",
    "checkerboard_world_corners = []\n",
    "for i in range(grid_size[0] * grid_size[1]):\n",
    "    grid_size_cv2 = tuple(reversed(grid_size)) \n",
    "    u_index, v_index = np.unravel_index(i, grid_size_cv2)\n",
    "        \n",
    "    # finding the (x,y) coordinates wrt the checkerboard\n",
    "    x_mm = (u_index) * square_size\n",
    "    y_mm = (v_index) * square_size\n",
    "    \n",
    "    checkerboard_world_corners.append([x_mm, y_mm, 0, 1])\n",
    "\n",
    "checkerboard_world_corners = np.stack(checkerboard_world_corners)\n",
    "\n",
    "checkerboard_image_corners = []\n",
    "for image in images_path:\n",
    "    corners = u.get_corners(image, grid_size)\n",
    "    checkerboard_image_corners.append(corners)\n",
    "    \n",
    "checkerboard_image_corners = np.concatenate(checkerboard_image_corners).reshape(-1, grid_size[0] * grid_size[1], 2)\n",
    "    \n",
    "all_params = [K[0,0], K[0,1], K[0,2], K[1,1], K[1,2]]\n",
    "all_r = []\n",
    "for i, R in enumerate(all_R):\n",
    "    r, theta = u.get_rot_axis_from_R(R)\n",
    "    all_r += r.tolist()\n",
    "    \n",
    "all_params += all_r + list(np.array(all_t).flatten())\n",
    "\n",
    "# least square computed using Levenberg-Marquardt\n",
    "least_square_output = least_squares(\n",
    "    u.compute_residuals,\n",
    "    all_params,\n",
    "    args=(checkerboard_world_corners, checkerboard_image_corners),\n",
    "    method=\"lm\"\n",
    ")\n",
    "\n",
    "# reconstructing the solutions\n",
    "n_images = (len(all_params) - 5) // 3 // 2\n",
    "alpha_u, skew, u_0, alpha_v, v_0 = least_square_output.x[:5]\n",
    "\n",
    "refined_K = np.stack([\n",
    "    [alpha_u, skew, u_0],\n",
    "    [0, alpha_v, v_0],\n",
    "    [0, 0, 1]\n",
    "])\n",
    "\n",
    "r = np.array(least_square_output.x[5:(5 + (n_images * 3))]).reshape(-1, 3)\n",
    "refined_t = np.array(least_square_output.x[-(n_images * 3):]).reshape(-1, 3)\n",
    "\n",
    "refined_R = np.stack([u.get_R_from_axis(r[i]) for i in range(n_images)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d43cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the image and extrinsics\n",
    "img_path = images_path[1]\n",
    "R1 = refined_R[1]\n",
    "t1 = refined_t[1]\n",
    "\n",
    "# combining R and t\n",
    "P = u.get_projection_matrix(refined_K, R1, t1)\n",
    "\n",
    "corners = u.get_corners(img_path, grid_size)\n",
    "projected_corners = []\n",
    "\n",
    "error = 0\n",
    "for index, corner in enumerate(corners):\n",
    "    u_coord = corner[0]\n",
    "    v_coord = corner[1]\n",
    "\n",
    "    grid_size_cv2 = tuple(reversed(grid_size))\n",
    "    u_index, v_index = np.unravel_index(index, grid_size_cv2)\n",
    "\n",
    "    # the coordinates of the corner w.r.t. the reference corner at position (0,0) of the corners array\n",
    "    x_mm = (u_index) * square_size\n",
    "    y_mm = (v_index) * square_size\n",
    "\n",
    "    point_m = np.array([x_mm, y_mm, 0, 1])\n",
    "\n",
    "    projected_u, projected_v = u.project(point_m, P)[0]\n",
    "    projected_corners.append((projected_u, projected_v))\n",
    "    \n",
    "    error += (projected_u - u_coord)**2 + (projected_v - v_coord)**2\n",
    "\n",
    "print(f\"Error: {error:.2f}\")\n",
    "print(f\"Mean error per corner: {error/len(corners):.2f}\")\n",
    "\n",
    "# showing the projected corners\n",
    "image = cv2.imread(img_path)\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # type: ignore\n",
    "\n",
    "for corner in projected_corners:\n",
    "    u_coord, v_coord = int(corner[0]), int(corner[1])\n",
    "    cv2.circle(image_rgb, (u_coord, v_coord), radius=5, color=(255, 0, 0), thickness=-1)\n",
    "\n",
    "px.imshow(image_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc743e34",
   "metadata": {},
   "source": [
    "## Exercise 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186af0b1",
   "metadata": {},
   "source": [
    "Optionally, you could add radial distortion compensation to the basic Zhang’s calibration procedure (refer to the complementary slides of `Lecture 3, p. 49`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf236644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "all_observed_corners = []\n",
    "all_world_corners = []\n",
    "\n",
    "grid_size_cv2 = tuple(reversed(grid_size))  # we want (rows, cols), not (cols, rows)\n",
    "for i, path in enumerate(images_path):\n",
    "    img_path = path\n",
    "    corners = u.get_corners_jack(img_path, grid_size)\n",
    "    world_corners = []\n",
    "    for index, corner in enumerate(corners):\n",
    "        u_coord = corner[0]\n",
    "        v_coord = corner[1]\n",
    "        u_index, v_index = np.unravel_index(index, grid_size_cv2)\n",
    "        x_mm = (u_index) * square_size\n",
    "        y_mm = (v_index) * square_size\n",
    "        world_corners.append([x_mm, y_mm, 0]) # NOT homogeneous\n",
    "    all_observed_corners.append(corners)\n",
    "    all_world_corners.append(np.array(world_corners))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d03833",
   "metadata": {},
   "source": [
    "At this point we have all the points of the world frame and all the observed corners (via openCV) of all the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4e98e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIAL GUESS\n",
    "V = []\n",
    "all_H = []\n",
    "\n",
    "# Estimate homographies\n",
    "for img in images_path:\n",
    "    _, H = u.get_homography(img, grid_size, square_size)\n",
    "    all_H.append(H)\n",
    "    \n",
    "    v_12 = u.get_v_vector(H, 1, 2)\n",
    "    v_11 = u.get_v_vector(H, 1, 1)\n",
    "    v_22 = u.get_v_vector(H, 2, 2)\n",
    "    \n",
    "    V.append(v_12)\n",
    "    V.append(v_11 - v_22)\n",
    "    \n",
    "V = np.array(V)\n",
    "# Estimate K\n",
    "K = u.get_intrinsic(V)\n",
    "\n",
    "# Estimate R_i, t_i, P_i for each image\n",
    "all_R = []\n",
    "all_t = []\n",
    "all_P = []\n",
    "\n",
    "for H in all_H:\n",
    "    R, t = u.get_extrinsic(K, H)\n",
    "    P = u.get_projection_matrix(K, R, t)\n",
    "    all_R.append(R)\n",
    "    all_t.append(t)\n",
    "    all_P.append(P)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f575eb01",
   "metadata": {},
   "source": [
    "Now we have $K^0, R_i^0, t_i^0 \\text{ and } P_i^0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f85873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESTIMATE k_1 and k_2\n",
    "k1, k2 = u.get_radial_distorsion(images_path, grid_size, square_size, K, all_P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a7fd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(k1, k2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb7ef05",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = images_path[1]\n",
    "R1 = all_R[1]\n",
    "t1 = all_t[1]\n",
    "\n",
    "corners = u.get_corners(img_path, grid_size)\n",
    "\n",
    "u_hat = corners[1][0]\n",
    "v_hat = corners[1][1]\n",
    "print(corners[1])\n",
    "\n",
    "new_u, new_v = u.undistort_point(u_hat, v_hat, K, k1, k2, 10)\n",
    "print(new_u, new_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3948a6c",
   "metadata": {},
   "source": [
    "Thus, we now have $K^0, R_i^0, t_i^0, P_i^0 \\text{ and } k_1^0, k_2^0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f1f369",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rvecs = []\n",
    "for R in all_R:\n",
    "    rvec, _ = u.get_rot_axis_from_R(R)\n",
    "    all_rvecs.append(rvec.reshape(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a710034a",
   "metadata": {},
   "outputs": [],
   "source": [
    "params0 = u.pack_params(K, k1, k2, all_rvecs, all_t)\n",
    "\n",
    "result = least_squares(\n",
    "    u.reprojection_residuals,\n",
    "    params0,\n",
    "    method=\"lm\",\n",
    "    args=(all_world_corners, all_observed_corners)\n",
    ")\n",
    "\n",
    "params_opt = result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6d33c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_opt, k1_opt, k2_opt, rvecs_opt, tvecs_opt = u.unpack_params(\n",
    "    params_opt,\n",
    "    len(all_observed_corners)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcb0e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(k1_opt, k2_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbdf64f",
   "metadata": {},
   "source": [
    "```pseudocode\n",
    "WorldPoints[j]        # chessboard points on Z = 0 plane\n",
    "ObservedPoints[i][j]  # (û, v̂) from cv2.findChessboardCorners\n",
    "Images i = 1..N\n",
    "Points j = 1..M\n",
    "```\n",
    "These NEVER change.\n",
    "\n",
    "**Linear initialization (ONCE)**\n",
    "```pseudocode\n",
    "for each image i:\n",
    "    H_i = estimate_homography(WorldPoints, ObservedPoints[i])\n",
    "\n",
    "K = estimate_intrinsics_from_homographies({H_i})\n",
    "\n",
    "for each image i:\n",
    "    (R_i, t_i) = estimate_extrinsics(K, H_i)\n",
    "```\n",
    "$\\rightarrow$ K⁰, R_i⁰, t_i⁰\n",
    "\n",
    "**Initial distortion estimation (ONCE)**\n",
    "```pseudocode\n",
    "for each image i:\n",
    "    for each point j:\n",
    "        (u_proj, v_proj) = project(WorldPoints[j], K⁰, R_i⁰, t_i⁰)\n",
    "        store (u_proj, v_proj)\n",
    "\n",
    "(k1⁰, k2⁰) = solve_radial_distortion(\n",
    "                projected_points,\n",
    "                ObservedPoints\n",
    "            )\n",
    "```\n",
    "$\\rightarrow$ K⁰, R_i⁰, t_i⁰, k1⁰, k2⁰\n",
    "\n",
    "**Nonlinear refinement loop**\n",
    "```pseudocode\n",
    "repeat until convergence:\n",
    "\n",
    "    # ---- STEP 1: Forward projection (MODEL → IMAGE) ----\n",
    "    for each image i:\n",
    "        for each point j:\n",
    "            (u_proj, v_proj) =\n",
    "                project(WorldPoints[j], Kᵏ, R_iᵏ, t_iᵏ)\n",
    "\n",
    "            (u_dist, v_dist) =\n",
    "                distort(u_proj, v_proj, k1ᵏ, k2ᵏ)\n",
    "\n",
    "            Residual[i][j] =\n",
    "                (u_dist - û[i][j],\n",
    "                 v_dist - v̂[i][j])\n",
    "\n",
    "    # ---- STEP 2: Parameter update ----\n",
    "    Update (K, R_i, t_i, k1, k2)\n",
    "    by minimizing:\n",
    "        Σ ||Residual[i][j]||²\n",
    "    using:\n",
    "        Gauss-Newton / Levenberg-Marquardt\n",
    "        \n",
    "    # ---- STEP 3: Convergence test ----\n",
    "    if change in parameters < ε OR\n",
    "       reprojection error decrease < ε:\n",
    "        break\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a600e934",
   "metadata": {},
   "source": [
    "## Exercise 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc17b30b",
   "metadata": {},
   "source": [
    "Optionally, you could compute the total reprojection error with radial distortion compensation and make a comparison to the one without compensation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c53b09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== INITIAL GUESS ==========\n",
    "V = []\n",
    "all_corners = []\n",
    "all_H = []\n",
    "\n",
    "# Estimate homographies\n",
    "for img in images_path:\n",
    "    # Detect corners\n",
    "    corners = u.get_corners_jack(img, grid_size)\n",
    "    _, H = u.get_homography(img, grid_size, square_size)\n",
    "    all_corners.append(corners)\n",
    "    all_H.append(H)\n",
    "    \n",
    "    v_12 = u.get_v_vector(H, 1, 2)\n",
    "    v_11 = u.get_v_vector(H, 1, 1)\n",
    "    v_22 = u.get_v_vector(H, 2, 2)\n",
    "    \n",
    "    V.append(v_12)\n",
    "    V.append(v_11 - v_22)\n",
    "    \n",
    "V = np.array(V)\n",
    "# Estimate K\n",
    "K = u.get_intrinsic(V)\n",
    "\n",
    "# Estimate R_i, t_i, P_i for each image\n",
    "all_R = []\n",
    "all_t = []\n",
    "all_P = []\n",
    "\n",
    "for H in all_H:\n",
    "    R, t = u.get_extrinsic(K, H)\n",
    "    P = u.get_projection_matrix(K, R, t)\n",
    "    all_R.append(R)\n",
    "    all_t.append(t)\n",
    "    all_P.append(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9294dc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K_opt, k1_opt, k2_opt, rvecs_opt, tvecs_opt\n",
    "all_R_opt = []\n",
    "all_t_opt = tvecs_opt\n",
    "all_P_opt = []\n",
    "for i in range(len(images_path)):\n",
    "    R_opt = u.get_R_from_axis(rvecs_opt[i])\n",
    "    P_opt = u.get_projection_matrix(K_opt, R_opt, all_t_opt[i])\n",
    "    all_R_opt.append(R_opt)\n",
    "    all_P_opt.append(P_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27ad9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_projected_points = []\n",
    "all_projected_points_opt = []\n",
    "grid_size_cv2 = tuple(reversed(grid_size))\n",
    "for i in range(len(images_path)):\n",
    "    proj_points = []\n",
    "    proj_points_opt = []\n",
    "    for index, corner in enumerate(all_corners[i]):\n",
    "        u_index, v_index = np.unravel_index(index, grid_size_cv2)\n",
    "        x_mm = (u_index) * square_size\n",
    "        y_mm = (v_index) * square_size\n",
    "        point_m = np.array([x_mm, y_mm, 0, 1])\n",
    "\n",
    "        u_proj, v_proj = u.project(point_m, all_P[i])[0]\n",
    "\n",
    "        proj_points.append([u_proj, v_proj])\n",
    "    all_projected_points.append(np.array(proj_points))\n",
    "    all_projected_points_opt.append(u.project_with_distortion(all_world_corners[i], K_opt, rvecs_opt[i], tvecs_opt[i], k1_opt, k2_opt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f77d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonradial_rerr = u.compute_reprojection_error(all_observed_corners, all_projected_points)\n",
    "radial_rerr = u.compute_reprojection_error(all_observed_corners, all_projected_points_opt)\n",
    "print(nonradial_rerr)\n",
    "print(radial_rerr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
